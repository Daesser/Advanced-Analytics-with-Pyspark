{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.conf\n",
    "import pyspark.sql\n",
    "SparkConf = pyspark.conf.SparkConf\n",
    "SparkSession = pyspark.sql.SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "            .appName(\"Intro\") \\\n",
    "            .config('spark.executor.memory', '2g') \\\n",
    "            .config('spark.driver.memory','4g') \\\n",
    "            .config(\"spark.sql.crossJoin.enabled\", \"true\")\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_user_artist_path = \"data/audioscrobbler_data/user_artist_data.txt\"\n",
    "raw_user_artist_data = spark.read.text(raw_user_artist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|              value|\n",
      "+-------------------+\n",
      "|       1000002 1 55|\n",
      "| 1000002 1000006 33|\n",
      "|  1000002 1000007 8|\n",
      "|1000002 1000009 144|\n",
      "|1000002 1000010 314|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# User / Artist / Count\n",
    "raw_user_artist_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|1134999\\t06Crazy ...|\n",
      "|6821360\\tPang Nak...|\n",
      "|10113088\\tTerfel,...|\n",
      "|10151459\\tThe Fla...|\n",
      "|6826647\\tBodensta...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Artist_ID / Name\n",
    "raw_artist_data = spark.read.text(\"data/audioscrobbler_data/artist_data.txt\")\n",
    "raw_artist_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|            value|\n",
      "+-----------------+\n",
      "| 1092764\\t1000311|\n",
      "| 1095122\\t1000557|\n",
      "| 6708070\\t1007267|\n",
      "|10088054\\t1042317|\n",
      "| 1195917\\t1042317|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Alias\n",
    "raw_artist_alias = spark.read.text(\"data/audioscrobbler_data/artist_alias.txt\")\n",
    "raw_artist_alias.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering is a technique that can filter out items that a user might like on the basis of reactions by similar users. It works by searching a large group of people and finding a smaller set of users with tastes similar to a particular user. \n",
    "Deciding that two users might both like the same song because they play many other songs that are the same is\n",
    "an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Least Squares Algorithm\n",
    "For further information:\n",
    "http://yifanhu.net/PUB/cf.pdf and \n",
    "https://dl.acm.org/doi/10.1007/978-3-540-68880-8_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+-----------+\n",
      "|min(user)|max(user)|min(artist)|max(artist)|\n",
      "+---------+---------+-----------+-----------+\n",
      "|       90|  2443548|          1|   10794401|\n",
      "+---------+---------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, min, max\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "# Min and Max user and artist ID\n",
    "user_artist_df = raw_user_artist_data.withColumn('user',\n",
    "                                    split(raw_user_artist_data['value'], ' ').\\\n",
    "                                    getItem(0).\\\n",
    "                                    cast(IntegerType()))\n",
    "user_artist_df = user_artist_df.withColumn('artist',\n",
    "                                    split(raw_user_artist_data['value'], ' ').\\\n",
    "                                    getItem(1).\\\n",
    "                                    cast(IntegerType()))\n",
    "user_artist_df = user_artist_df.withColumn('count',\n",
    "                                    split(raw_user_artist_data['value'], ' ').\\\n",
    "                                    getItem(2).\\\n",
    "                                    cast(IntegerType())).drop('value')\n",
    "user_artist_df.select([min(\"user\"), max(\"user\"), min(\"artist\"),\\\n",
    "                                    max(\"artist\")]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|      id|                name|\n",
      "+--------+--------------------+\n",
      "| 1134999|        06Crazy Life|\n",
      "| 6821360|        Pang Nakarin|\n",
      "|10113088|Terfel, Bartoli- ...|\n",
      "|10151459| The Flaming Sidebur|\n",
      "| 6826647|   Bodenstandig 3000|\n",
      "+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "artist_by_id = raw_artist_data.withColumn('id', split(col('value'), '\\s+', 2).\\\n",
    "                                            getItem(0).\\\n",
    "                                            cast(IntegerType()))\n",
    "artist_by_id = artist_by_id.withColumn('name', split(col('value'), '\\s+', 2).\\\n",
    "                                            getItem(1).\\\n",
    "                                            cast(StringType())).drop('value')\n",
    "artist_by_id.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|  artist|  alias|\n",
      "+--------+-------+\n",
      "| 1092764|1000311|\n",
      "| 1095122|1000557|\n",
      "| 6708070|1007267|\n",
      "|10088054|1042317|\n",
      "| 1195917|1042317|\n",
      "+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_alias = raw_artist_alias.withColumn('artist',\n",
    "                                            split(col('value'), '\\s+').\\\n",
    "                                            getItem(0).\\\n",
    "                                            cast(IntegerType())).\\\n",
    "                                withColumn('alias',\n",
    "                                            split(col('value'), '\\s+').\\\n",
    "                                            getItem(1).\\\n",
    "                                            cast(StringType())).\\\n",
    "                                            drop('value')\n",
    "artist_alias.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|     id|          name|\n",
      "+-------+--------------+\n",
      "|1000311| Steve Winwood|\n",
      "|1092764|Winwood, Steve|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_by_id.filter(artist_by_id.id.isin(1092764, 1000311)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24296858"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import broadcast, when\n",
    "train_data = user_artist_df.join(broadcast(artist_alias),'artist', how='left')\n",
    "train_data = train_data.withColumn('artist',when(col('alias').isNull(), col('artist')).otherwise(col('alias')))\n",
    "train_data = train_data.withColumn('artist', col('artist').cast(IntegerType())).drop('alias')\n",
    "train_data.cache()\n",
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "model = ALS(rank=10, seed=0, maxIter=5, regParam=0.1,\n",
    "implicitPrefs=True, alpha=1.0, userCol='user',\n",
    "itemCol='artist', ratingCol='count').fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |features                                                                                                                     |\n",
      "+---+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "|90 |[0.16020626, 0.20717518, -0.17194685, 0.060384676, 0.0627277, 0.54658705, -0.40481892, 0.43657345, -0.10396776, -0.042728294]|\n",
      "+---+-----------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.userFactors.show(1, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "|     id|           name|\n",
      "+-------+---------------+\n",
      "|   1180|     David Gray|\n",
      "|    378|  Blackalicious|\n",
      "|    813|     Jurassic 5|\n",
      "|1255340|The Saw Doctors|\n",
      "|    942|         Xzibit|\n",
      "+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_id = 2093760\n",
    "existing_artist_ids = train_data.filter(train_data.user == user_id).select(\"artist\").collect()\n",
    "existing_artist_ids = [i[0] for i in existing_artist_ids]\n",
    "artist_by_id.filter(col('id').isin(existing_artist_ids)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|   user|     recommendations|\n",
      "+-------+--------------------+\n",
      "|2093760|[{2814, 0.0294106...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_subset = train_data.select('user').where(col('user') == user_id).distinct()\n",
    "top_predictions = model.recommendForUserSubset(user_subset, 5)\n",
    "top_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|   user|     recommendations|\n",
      "+-------+--------------------+\n",
      "|2093760|[{2814, 0.0294106...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_subset = train_data.select('user').where(col('user') == user_id).distinct()\n",
    "top_predictions = model.recommendForUserSubset(user_subset, 5)\n",
    "top_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user                                    recommendations\n",
      "0  2093760  [(2814, 0.029410677030682564), (1300642, 0.028...\n",
      "+-------+----------+\n",
      "|     id|      name|\n",
      "+-------+----------+\n",
      "|   2814|   50 Cent|\n",
      "|   4605|Snoop Dogg|\n",
      "|1007614|     Jay-Z|\n",
      "|1001819|      2Pac|\n",
      "|1300642|  The Game|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_predictions_pandas = top_predictions.toPandas()\n",
    "print(top_predictions_pandas)\n",
    "recommended_artist_ids = [i[0] for i in top_predictions_pandas.\\\n",
    "recommendations[0]]\n",
    "artist_by_id.filter(col('id').isin(recommended_artist_ids)).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
