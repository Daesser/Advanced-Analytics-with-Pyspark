{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92395ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.conf\n",
    "import pyspark.sql\n",
    "SparkConf = pyspark.conf.SparkConf\n",
    "SparkSession = pyspark.sql.SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "            .appName(\"Intro\") \\\n",
    "            .config('spark.executor.memory', '2g') \\\n",
    "            .config('spark.driver.memory','8g') \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "415d910e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "|  _c0|  _c1|              _c2|         _c3|         _c4|         _c5|    _c6|   _c7|   _c8|   _c9|   _c10|    _c11|\n",
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| id_1| id_2|     cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "|37291|53113|0.833333333333333|           ?|           1|           ?|      1|     1|     1|     1|      0|    TRUE|\n",
      "|39086|47614|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|70031|70237|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|84795|97439|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|36950|42116|                1|           ?|           1|           1|      1|     1|     1|     1|      1|    TRUE|\n",
      "|42413|48491|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|25965|64753|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|49451|90407|                1|           ?|           1|           ?|      1|     1|     1|     1|      0|    TRUE|\n",
      "|39932|40902|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|46626|47940|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|48948|98379|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "| 4767| 4826|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|45463|69659|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|11367|13169|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|10782|89636|                1|           ?|           1|           ?|      1|     0|     1|     1|      1|    TRUE|\n",
      "|26206|39147|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|16662|27083|                1|           1|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|18823|30204|                1|           1|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "|38545|85418|                1|           ?|           1|           ?|      1|     1|     1|     1|      1|    TRUE|\n",
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# This may take some time if you work locally\n",
    "#prev = spark.read.csv(\"linkage/block*.csv\")\n",
    "prev = spark.read.csv(\"linkage/block_1.csv\")\n",
    "prev.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badad8ab",
   "metadata": {},
   "source": [
    "The ? are missing values and the header wasn't read correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "540c39ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can infer the schema else it is string\n",
    "# Note: To perform the schema inference. Spark must pass over the ddata set twice (detecting and parsing schema)\n",
    "# If you know the schema you can define it using StructField and StructType:\n",
    "\"\"\"\n",
    "from pyspark.sql.types import *\n",
    "schema = StructType([StructField(\"id_1\", IntegerType(), False),\n",
    "StructField(\"id_2\", StringType(), False),\n",
    "StructField(\"cmp_fname_c1\", DoubleType(), False)])\n",
    "spark.read.schema(schema).csv(\"...\")\n",
    "or\n",
    "schema = \"id_1 INT, id_2 INT, cmp_fname_c1 DOUBLE\"\n",
    "\"\"\"\n",
    "prev.printSchema()\n",
    "parsed = spark.read \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"nullValue\", \"?\") \\\n",
    "            .option(\"inferSchema\", \"true\") \\\n",
    "            .csv(\"linkage/block_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c0c2252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| id_1| id_2|     cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "|37291|53113|0.833333333333333|        null|         1.0|        null|      1|     1|     1|     1|      0|    true|\n",
      "|39086|47614|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|70031|70237|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|84795|97439|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|36950|42116|              1.0|        null|         1.0|         1.0|      1|     1|     1|     1|      1|    true|\n",
      "|42413|48491|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|25965|64753|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|49451|90407|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      0|    true|\n",
      "|39932|40902|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|46626|47940|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|48948|98379|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "| 4767| 4826|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|45463|69659|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|11367|13169|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|10782|89636|              1.0|        null|         1.0|        null|      1|     0|     1|     1|      1|    true|\n",
      "|26206|39147|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|16662|27083|              1.0|         1.0|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|18823|30204|              1.0|         1.0|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|38545|85418|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|28963|39172|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c54e1049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id_1=37291, id_2=53113, cmp_fname_c1=0.833333333333333, cmp_fname_c2=None, cmp_lname_c1=1.0, cmp_lname_c2=None, cmp_sex=1, cmp_bd=1, cmp_bm=1, cmp_by=1, cmp_plz=0, is_match=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "parsed.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aafdee",
   "metadata": {},
   "source": [
    "## Analyzing Data with the DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c0589ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574913"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba63dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "| id_1| id_2|     cmp_fname_c1|cmp_fname_c2|cmp_lname_c1|cmp_lname_c2|cmp_sex|cmp_bd|cmp_bm|cmp_by|cmp_plz|is_match|\n",
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "|37291|53113|0.833333333333333|        null|         1.0|        null|      1|     1|     1|     1|      0|    true|\n",
      "|39086|47614|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|70031|70237|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|84795|97439|              1.0|        null|         1.0|        null|      1|     1|     1|     1|      1|    true|\n",
      "|36950|42116|              1.0|        null|         1.0|         1.0|      1|     1|     1|     1|      1|    true|\n",
      "+-----+-----+-----------------+------------+------------+------------+-------+------+------+------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a885c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_1: integer (nullable = true)\n",
      " |-- id_2: integer (nullable = true)\n",
      " |-- cmp_fname_c1: double (nullable = true)\n",
      " |-- cmp_fname_c2: double (nullable = true)\n",
      " |-- cmp_lname_c1: double (nullable = true)\n",
      " |-- cmp_lname_c2: double (nullable = true)\n",
      " |-- cmp_sex: integer (nullable = true)\n",
      " |-- cmp_bd: integer (nullable = true)\n",
      " |-- cmp_bm: integer (nullable = true)\n",
      " |-- cmp_by: integer (nullable = true)\n",
      " |-- cmp_plz: integer (nullable = true)\n",
      " |-- is_match: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "039039e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|is_match| count|\n",
      "+--------+------+\n",
      "|   false|572820|\n",
      "|    true|  2093|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "parsed.groupBy(\"is_match\").count().orderBy(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5519c3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id_1: int, id_2: int, cmp_fname_c1: double, cmp_fname_c2: double, cmp_lname_c1: double, cmp_lname_c2: double, cmp_sex: int, cmp_bd: int, cmp_bm: int, cmp_by: int, cmp_plz: int, is_match: boolean]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a25398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use SQL syntax create temporary table\n",
    "parsed.createOrReplaceTempView(\"linkage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4af902c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|is_match|   cnt|\n",
      "+--------+------+\n",
      "|   false|572820|\n",
      "|    true|  2093|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "            SELECT is_match, COUNT(*) cnt\n",
    "            FROM linkage\n",
    "            GROUP BY is_match\n",
    "            ORDER BY cnt DESC\n",
    "        \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5066315f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|      cmp_fname_c1|      cmp_fname_c2|\n",
      "+-------+------------------+------------------+\n",
      "|  count|            574811|             10325|\n",
      "|   mean|0.7127592938253411|0.8977586763518969|\n",
      "| stddev|0.3889286452463531|0.2742577520430532|\n",
      "|    min|               0.0|               0.0|\n",
      "|    max|               1.0|               1.0|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary = parsed.describe()\n",
    "summary.select(\"summary\", \"cmp_fname_c1\", \"cmp_fname_c2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20560b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = parsed.where(\"is_match = true\")\n",
    "misses  = parsed.where(\"is_match = false\")\n",
    "matchSummary = matches.describe()\n",
    "missSummary = misses.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6fc0474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+--------------------+-------------------+---+------+\n",
      "|       field| count|                mean|             stddev|min|   max|\n",
      "+------------+------+--------------------+-------------------+---+------+\n",
      "|        id_1|574913|  33271.962171667714| 23622.669425933756|  1| 99894|\n",
      "|        id_2|574913|    66564.6636865056|  23642.00230967228|  6|100000|\n",
      "|cmp_fname_c1|574811|  0.7127592938253411| 0.3889286452463531|0.0|   1.0|\n",
      "|cmp_fname_c2| 10325|  0.8977586763518969| 0.2742577520430532|0.0|   1.0|\n",
      "|cmp_lname_c1|574913|  0.3155724578100624| 0.3342494687554245|0.0|   1.0|\n",
      "|cmp_lname_c2|   239|  0.3269155414552904| 0.3783092020540671|0.0|   1.0|\n",
      "|     cmp_sex|574913|  0.9550923357099248|0.20710152240504442|  0|     1|\n",
      "|      cmp_bd|574851| 0.22475563232907309| 0.4174216587235557|  0|     1|\n",
      "|      cmp_bm|574851|  0.4886361857246487| 0.4998712818281637|  0|     1|\n",
      "|      cmp_by|574851| 0.22266639529199742| 0.4160365041645591|  0|     1|\n",
      "|     cmp_plz|573618|0.005494946113964...|0.07392402321301972|  0|     1|\n",
      "+------------+------+--------------------+-------------------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Panda conversion\n",
    "summary_p = summary.toPandas()\n",
    "summary_p = summary_p.set_index('summary').transpose().reset_index()\n",
    "summary_p = summary_p.rename(columns={'index':'field'})\n",
    "summary_p = summary_p.rename_axis(None, axis=1)\n",
    "summaryT = spark.createDataFrame(summary_p)\n",
    "summaryT.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df385f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- field: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- mean: string (nullable = true)\n",
      " |-- stddev: string (nullable = true)\n",
      " |-- min: string (nullable = true)\n",
      " |-- max: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summaryT.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30f13f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- field: string (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- mean: string (nullable = true)\n",
      " |-- stddev: string (nullable = true)\n",
      " |-- min: string (nullable = true)\n",
      " |-- max: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- field: string (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- mean: double (nullable = true)\n",
      " |-- stddev: string (nullable = true)\n",
      " |-- min: string (nullable = true)\n",
      " |-- max: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- field: string (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- mean: double (nullable = true)\n",
      " |-- stddev: double (nullable = true)\n",
      " |-- min: string (nullable = true)\n",
      " |-- max: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- field: string (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- mean: double (nullable = true)\n",
      " |-- stddev: double (nullable = true)\n",
      " |-- min: double (nullable = true)\n",
      " |-- max: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- field: string (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- mean: double (nullable = true)\n",
      " |-- stddev: double (nullable = true)\n",
      " |-- min: double (nullable = true)\n",
      " |-- max: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "# Cast to double type\n",
    "for c in summaryT.columns:\n",
    "    if c == 'field':\n",
    "        continue\n",
    "    summaryT = summaryT.withColumn(c, summaryT[c].cast(DoubleType()))\n",
    "    summaryT.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a23a76b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import DoubleType\n",
    "def pivot_summary(desc):\n",
    "    # convert to pandas dataframe\n",
    "    desc_p = desc.toPandas()\n",
    "    # transpose\n",
    "    desc_p = desc_p.set_index('summary').transpose().reset_index()\n",
    "    desc_p = desc_p.rename(columns={'index':'field'})\n",
    "    desc_p = desc_p.rename_axis(None, axis=1)\n",
    "    # convert to Spark dataframe\n",
    "    descT = spark.createDataFrame(desc_p)\n",
    "    # convert metric columns to double from string\n",
    "    for c in descT.columns:\n",
    "        if c == 'field':\n",
    "            continue\n",
    "        else:\n",
    "            descT = descT.withColumn(c, descT[c].cast(DoubleType()))\n",
    "    return descT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e2041f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_summaryT = pivot_summary(matchSummary)\n",
    "miss_summaryT = pivot_summary(missSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78bc6ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-------------------+\n",
      "|       field|   total|              delta|\n",
      "+------------+--------+-------------------+\n",
      "|     cmp_plz|573618.0| 0.9524975516429005|\n",
      "|cmp_lname_c2|   239.0| 0.8136949970410103|\n",
      "|      cmp_by|574851.0| 0.7763379425859384|\n",
      "|      cmp_bd|574851.0| 0.7732820129086737|\n",
      "|cmp_lname_c1|574913.0| 0.6844795197261291|\n",
      "|      cmp_bm|574851.0|  0.510834819548174|\n",
      "|cmp_fname_c1|574811.0|0.28531156828518667|\n",
      "|cmp_fname_c2| 10325.0|0.09900440489032714|\n",
      "|     cmp_sex|574913.0|0.03452211590529575|\n",
      "+------------+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "match_summaryT.createOrReplaceTempView(\"match_desc\")\n",
    "miss_summaryT.createOrReplaceTempView(\"miss_desc\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT a.field, a.count + b.count total, a.mean - b.mean delta\n",
    "FROM match_desc a INNER JOIN miss_desc b ON a.field = b.field\n",
    "WHERE a.field NOT IN (\"id_1\", \"id_2\")\n",
    "ORDER BY delta DESC, total DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ba4e6",
   "metadata": {},
   "source": [
    "## Scoring and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "984c65a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cmp_lname_c1 + cmp_plz + cmp_by + cmp_bd + cmp_bm'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_features = [\"cmp_lname_c1\", \"cmp_plz\", \"cmp_by\", \"cmp_bd\", \"cmp_bm\"]\n",
    "sum_expression = \" + \".join(good_features)\n",
    "sum_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16406fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|score|is_match|\n",
      "+-----+--------+\n",
      "|  4.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  4.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  4.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "|  5.0|    true|\n",
      "+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "scored = parsed.fillna(0, subset=good_features).\\\n",
    "withColumn('score', expr(sum_expression)).\\\n",
    "select('score', 'is_match')\n",
    "scored.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "638b02db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+\n",
      "|above|true| false|\n",
      "+-----+----+------+\n",
      "| true|2087|    66|\n",
      "|false|   6|572754|\n",
      "+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def crossTabs(scored: DataFrame, t: DoubleType) -> DataFrame:\n",
    "    return scored.selectExpr(f\"score >= {t} as above\", \"is_match\").\\\n",
    "groupBy(\"above\").pivot(\"is_match\", (\"true\", \"false\")).\\\n",
    "count()\n",
    "crossTabs(scored, 4.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9af0f500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+\n",
      "|above|true| false|\n",
      "+-----+----+------+\n",
      "| true|2093| 59729|\n",
      "|false|null|513091|\n",
      "+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crossTabs(scored, 2.0).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
